---
layout: post
mathjax: true
title: "Visualizing the Variational Autoencoder"
date: 2020-01-30
comments: true
author: "Chinmay Savadikar"
categories: post
tldr: Visualizing the latent space of a VAE
thumbnail: "vae.gif"
badges:
  - name: vae
    url: https://colab.research.google.com/github/savadikarc/vae/blob/master/vae.ipynb
  - name: conditional_vae
    url: https://colab.research.google.com/github/savadikarc/vae/blob/master/conditional_vae.ipynb
repository: https://github.com/savadikarc/vae
---

<link href="/assets/vae_vis/style.css" rel="stylesheet">

The purpose of this post is to put into writing Variational Autoencoders the way I have understood it. This serves a dual purpose: It forces me to think about my understanding in-depth and it will hopefully clear some doubts for others in my position. This part of the post will focus on a brief summary of VAEs, followed by some visualizations on MNIST. We will also see some visualizations of the Conditional VAE, which can generate class-conditional images. I will leave a detailed explanation to the next post.

The code used for the experiments and generating the images is available on [GitHub](https://github.com/savadikarc/vae). I find the notebook interface convenient for such experiments, hence all the code is formatted in two notebooks: vae.ipynb and conditional_vae.ipynb. Plus, Google Colab makes setting up the experiemnt up easier!

### Variational Autoencoder

The code to reproduce all the figures and training the variational autoencoder can be found in this [Colab notebook](https://colab.research.google.com/github/savadikarc/vae/blob/master/vae.ipynb).

Variational Autoencoders have been shown to be capable of generating novel, realistic images. Let us first set the premise of the problem. The goal is to generate images, which we denote by $$ x $$. We assume that an image $$ x $$ depends on some latent variables $$ z $$, which encodes some information about the image. In a later part of this post, we will visualize what these latent variables might be encoding. The latent variable $$ z $$ is sampled from a probability distribution $$ p_\theta(z) $$, called as the prior over $$ z $$. We assume that this distribution takes the form of a Normal distribution, i.e. $$ z \sim \mathcal{N}(0, 1) $$.

The representation $$ z $$ is called latent, meaning hidden, because we cannot directly observe it as we do with our data (images). Instead, we have to infer it from the data. This is done by learning the posterior distribution $$ p_\theta(z \vert x) $$, i.e., when we don’t know what our $$ z $$’s look like, we will learn them from the data. We force this distribution to be as close as possible to the prior over $$ z $$: $$ p_\theta(z) $$. Using the $$ z $$ sampled from the posterior distribution $$ p_\theta(z \vert x) $$, we can now learn the posterior distribution over our data - $$ p_\theta(x \vert z) $$. When we have learned our distribution $$ p_\theta(x \vert z) $$, we can sample a random vector from $$ \mathcal{N}(0, 1) $$, and generate a novel image, since we forced the posterior over $$ z $$ to be as close to the prior $$ p_\theta(z) $$ as possible. In doing this, we are trying to maximize the likelihood of our data: $$ p_\theta(X) $$.

We can use a neural network to parameterize both $$ p_\theta(z \vert x) $$ and $$ p_\theta(x \vert z) $$, which is where the term variational autoencoder comes from. However, $$ p_\theta(z \vert x) $$ is intractable. The algorithm ‘Autoencoding Variational Bayes’ proposes many tricks that make learning an otherwise intractable posterior $$ p_\theta(z \vert x) $$ tracktable, by learning an approximation $$ q_\phi(z \vert x) $$ and using the reparameterization trick. Therefore, the encoder parameterizes $$ q_\phi(z \vert x) $$ and the decoder parameterizes $$ p_\theta(x \vert z) $$. More on this in the next post.

So, what does the latent vector $$ z $$ encode? Since each element of $$ z $$ is just a number, it does not mean much to us directly. However, we can visualize what image is generated by a particular value of vector $$ z $$. The figure below shows the MNIST manifold learned by the VAE. I have used the dimensions of $$ z $$ to be 2. This limits the capacity of the model, but allows for some cool visualizations. By setting the values of $$ z_1 $$ and $$ z_2 $$ (elements of the vector $$ z $$) to (almost) cover the support of the prior $$ p_\theta(z) $$, and taking all the combinations of the elements, we can generate images using the decoder and see the effect. Recall the Normal distribution. The horizontal axis represents $$ z_1 $$ and the vertical axis represents $$ z_2 $$. The center of the grid corresponds to $$ (z_1, z_2) = (0, 0) $$.

<div class="row md-img-container">

	<div class="col-xl-6 col-lg-6 col-md-12 col-sm-12 col-xs-12 md-imgs">
		<div class="row">
			<img class="img-fluid" src="/assets/vae_vis/mnist_manifold.png" height="400px" width="400px">
		</div>
		<div class="row md-imgs">
			<p>MNIST Manifold</p>
		</div>
	</div>
	
	<div class="col-xl-6 col-lg-6 col-md-12 col-sm-12 col-xs-12 md-imgs">
		<div class="row">
			<img class="img-fluid" src="/assets/vae_vis/vae_latent_plot.png" height="400px" width="400px">
		</div>
		<div class="row">
			<p>Plot of the latent vector of the VAE</p>
		</div>
	</div>

</div>

Up till now, we were sampling novel images. Now, let’s see what the encoder is encoding from the input images $$ x $$. The figure below shows the scatter plot of $$ z $$ sampled from the posterior distribution $$ q_\phi(z \vert x) $$. We do this by passing an input image through the decoder. The encoder seems to have assigned different clusters to different digits. The plot corroborates with the manifold, 1 is at the top left, 0 at the bottom right, 7 on the right, etc.

We can even interpolate between two digits: to go from 1 to 0, we need to pass through 6, 2 and then to 0. Or to go 1 to 2, we must go through 6. We can see that in the gifs below. Very cool!

| ![1 to 0](/assets/vae_vis/interpolations/1to0.gif) | ![1 to 2](/assets/vae_vis/interpolations/1to2.gif) | ![1 to 3](/assets/vae_vis/interpolations/1to3.gif) | ![1 to 4](/assets/vae_vis/interpolations/1to4.gif) | ![1 to 5](/assets/vae_vis/interpolations/1to5.gif) | ![1 to 6](/assets/vae_vis/interpolations/1to6.gif) | ![1 to 7](/assets/vae_vis/interpolations/1to7.gif) | ![1 to 8](/assets/vae_vis/interpolations/1to8.gif) | ![1 to 9](/assets/vae_vis/interpolations/1to9.gif) |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| 1-0 | 1-2 | 1-3 | 1-4 | 1-5 | 1-6 | 1-7 | 1-8 | 1-9 |

| ![6 to 0](/assets/vae_vis/interpolations/6to0.gif) | ![6 to 1](/assets/vae_vis/interpolations/6to1.gif) | ![6 to 2](/assets/vae_vis/interpolations/6to2.gif) | ![6 to 3](/assets/vae_vis/interpolations/6to3.gif) | ![6 to 4](/assets/vae_vis/interpolations/6to4.gif) | ![6 to 5](/assets/vae_vis/interpolations/6to5.gif) | ![6 to 7](/assets/vae_vis/interpolations/6to7.gif) | ![6 to 8](/assets/vae_vis/interpolations/6to8.gif) | ![6 to 9](/assets/vae_vis/interpolations/6to9.gif) |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| 6-0 | 6-1 | 6-2 | 6-3 | 6-4 | 6-5 | 6-7 | 6-8 | 6-9 |

### Conditional Variational Autoencoder

The code to reproduce all the figures and training the conditional variational autoencoder can be found in this [Colab notebook](https://colab.research.google.com/github/savadikarc/vae/blob/master/conditional_vae.ipynb).

In VAEs, we try to model the likelihood of the entire data. The latent vector has to encode the class as well, and we don’t have any control over the class for which we are generating an image. However, in conditional VAE, we can generate an image from a particular class by learning distributions $$ p_\theta(z \vert x, c) $$ and $$ p_\theta(x \vert z, c) $$. Now, $$ z $$ is a vector for one particular class, and we define the prior over $$ z $$ as $$ p_\theta(z \vert c) $$, i.e., a conditional probability distribution. Again, we assume this to be a Normal distribution. The goal now is to learn the conditional likelihood of data: $$ p_\theta(X \vert c) $$. We can see the generated images below. The generated images look much cleaner, and the latent variables encode something meaningful like the properties of the images instead of assigning different clusters to samples. For example, $$ z_1 $$ seems to encode the slant of the image for class '1'.

<div class="row md-img-container">
	
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_0.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_1.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_2.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_3.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_4.png" height="190px" width="190px">
		</div>
	
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_5.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_6.png" height="190px" width="190px">
		</div>
		<div class="col-xl-3 col-lg-3 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_7.png" height="190px" width="190px">
		</div>
		<div class="col-xl-6 col-lg-6 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_8.png" height="190px" width="190px">
		</div>
		<div class="col-xl-6 col-lg-6 col-md-6 col-sm-6 col-xs-6 md-imgs">
			<img class="img-fluid" src="/assets/vae_vis/cvae/conditional_vae_mnist_manifold_9.png" height="190px" width="190px">
		</div>
	
</div>


If we look at the plot of $$ z_1 $$ vs. $$ z_2 $$ for $$ z $$ sampled from the posterior over $$ z $$, we can see that all the points are clustered at a single point, regardless of the class. This means that the vector z encodes the properties of the images, and the class of the image is decoupled from the latent representation.

<div class="row md-img-container">
	<div class="col md-imgs">
		<div class="row">
			<img class="img-fluid" src="/assets/vae_vis/cvae/latent_plot.png" height="400px" width="400px">
		</div>
		<div class="row">
			<p>Plot of the latent vector of the CVAE</p>
		</div>
	</div>
</div>
